# Session Log: 2026-02-01 - Topsi Voice Integration & LLM Response Fix

## Summary
Fixed critical voice interaction issues with Topsi and Nora, including adding voice input to Topsi's full page and fixing a bug where the LLM was echoing user requests instead of generating actual responses.

## Issues Addressed

### 1. Nora Voice Not Responding
- **Problem**: Nora picking up voice but returning "ElevenLabs API key not configured" error
- **Solution**: Updated voice config to use Chatterbox TTS instead of ElevenLabs

### 2. STT Quota Exceeded
- **Problem**: OpenAI STT quota exceeded, transcription failing
- **Solution**: Created local Whisper STT server (`scripts/whisper_server.py`) running on port 8101

### 3. Topsi Full Page Missing Voice Input
- **Problem**: Voice input only worked in floating widget, not on main Topsi page
- **Solution**: Added push-to-talk voice input to `frontend/src/pages/topsi.tsx`:
  - Microphone button with hold-to-record
  - Audio level visualization
  - Speaker toggle for TTS output

### 4. LLM Echoing Requests (Critical Bug)
- **Problem**: Topsi LLM calling `respond_to_user` with the user's question instead of generating a response
  - Example: User says "Tell me a story" â†’ LLM returns `{"message":"Tell me a random story."}` instead of an actual story
- **Root Cause**: Ambiguous tool description for `respond_to_user` didn't make it clear the LLM should compose the response
- **Solution**:
  1. Updated tool description in `crates/topsi/src/tools/mod.rs`:
     - Made explicit that LLM must "compose and write out your complete response"
     - Added example: "if a user asks 'tell me a story', you should write an actual story"
  2. Updated system prompt in `crates/topsi/src/agent.rs`:
     - Added `respond_to_user` to available tools list
     - Added "How to Respond" section with explicit examples
     - Emphasized: "NEVER just echo the user's request back"

## Files Modified
- `crates/topsi/src/agent.rs` - Updated system prompt with respond_to_user instructions
- `crates/topsi/src/tools/mod.rs` - Clarified respond_to_user tool description
- `crates/topsi/src/topology/voice.rs` - New voice topology module
- `crates/nora/src/voice/stt.rs` - Added LocalWhisperSTT provider
- `crates/nora/src/voice/engine.rs` - Integration for local Whisper
- `frontend/src/pages/topsi.tsx` - Added voice input UI
- `scripts/whisper_server.py` - New local Whisper STT server

## Services Configuration
- **Frontend**: http://localhost:3000
- **Backend**: http://localhost:3003
- **Chatterbox TTS**: http://localhost:8100 (CUDA-enabled)
- **Whisper STT**: http://localhost:8101 (CUDA, base model for accuracy)

## Commit
```
cc05180 Add voice capabilities to Topsi and fix LLM response echo bug
```

## Next Steps
- Test Topsi voice interaction end-to-end
- Monitor for any remaining echo issues with different LLM providers
- Consider adding conversation history to Topsi (currently shows `History: 0 messages`)
- Improve Chatterbox TTS speed (currently ~15 seconds per response)
