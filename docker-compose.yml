version: '3.8'

services:
  # Main application
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: pcg-cc-mcp
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Enable GPU access for Chatterbox TTS and Ollama acceleration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - HOST=0.0.0.0
      - BACKEND_PORT=3001
      - FRONTEND_PORT=3000
      - RUST_LOG=info
      - PCG_ASSET_DIR=/app/dev_assets
      # Ollama Configuration (Local LLM)
      - OLLAMA_BASE_URL=http://localhost:11434
      - OLLAMA_MODEL=deepseek-r1
      # Chatterbox TTS Configuration (Local Voice) - Using host Coqui TTS
      - CHATTERBOX_URL=http://172.17.0.1:8102
      - CHATTERBOX_PORT=8102
      - CHATTERBOX_DEVICE=cuda
      # Local Whisper STT (Sovereign Stack) - Using host Whisper server
      - WHISPER_URL=http://172.17.0.1:8101
      # NORA AI Assistant Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - NORA_LLM_MODEL=${NORA_LLM_MODEL:-deepseek-r1}
      - NORA_LLM_TEMPERATURE=${NORA_LLM_TEMPERATURE:-0.7}
      - NORA_LLM_MAX_TOKENS=${NORA_LLM_MAX_TOKENS:-2000}
      # NORA Voice/TTS/STT Configuration (Optional - enables voice features)
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY:-}
      - AZURE_SPEECH_KEY=${AZURE_SPEECH_KEY:-}
      - AZURE_SPEECH_REGION=${AZURE_SPEECH_REGION:-eastus}
      # Twilio Phone Integration (Optional - enables phone calls to NORA)
      # NOTE: Twilio now uses NORA's voice engine (OpenAI/ElevenLabs) for TTS.
      # The TWILIO_TTS_VOICE is only used as a fallback if NORA voice fails.
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID:-}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN:-}
      - TWILIO_PHONE_NUMBER=${TWILIO_PHONE_NUMBER:-}
      - TWILIO_WEBHOOK_BASE_URL=${TWILIO_WEBHOOK_BASE_URL:-}
      - TWILIO_SPEECH_LANGUAGE=${TWILIO_SPEECH_LANGUAGE:-en-GB}
      - TWILIO_TTS_VOICE=${TWILIO_TTS_VOICE:-Polly.Amy}  # Fallback voice only
      - TWILIO_MAX_CALL_DURATION=${TWILIO_MAX_CALL_DURATION:-3600}
      - TWILIO_RECORDING_ENABLED=${TWILIO_RECORDING_ENABLED:-false}
      - TWILIO_GREETING_MESSAGE=${TWILIO_GREETING_MESSAGE:-}
    volumes:
      # Persist database
      - ./dev_assets:/app/dev_assets
      # Persist repositories
      - repos_data:/repos
      # Access backups for restore on container startup
      - ./backups:/app/backups
      # Share frontend dist with nginx
      - frontend-dist:/app/frontend/dist
    ports:
      - "3001:3001"        # Main application API
      - "11434:11434"      # Ollama API (local LLM)
      - "8100:8100"        # Chatterbox TTS API (local voice)
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1:3001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      app-network:
        aliases:
          - app
          - pcg-cc-mcp

  # Automated database backup service
  db-backup:
    image: alpine:latest
    container_name: pcg-db-backup
    restart: unless-stopped
    environment:
      - BACKUP_INTERVAL=${BACKUP_INTERVAL:-86400}  # Default: daily (24h in seconds)
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-7}  # Keep last 7 days
    volumes:
      - ./dev_assets:/data:ro  # Read-only access to database
      - ./backups:/backups     # Backup storage location
    command: >
      sh -c '
        echo "üîÑ Backup service started"
        echo "üìÖ Backup interval: $$BACKUP_INTERVAL seconds"
        echo "üóëÔ∏è  Retention: $$BACKUP_RETENTION_DAYS days"
        
        # Create backups directory if it does not exist
        mkdir -p /backups
        
        # Initial backup on startup
        TIMESTAMP=$$(date +%Y%m%d_%H%M%S)
        if [ -f /data/db.sqlite ]; then
          echo "üì¶ Creating initial backup: backup_$$TIMESTAMP.sqlite"
          cp /data/db.sqlite /backups/backup_$$TIMESTAMP.sqlite
          echo "‚úÖ Initial backup complete"
        else
          echo "‚ö†Ô∏è  No database found at /data/db.sqlite"
        fi
        
        # Periodic backup loop
        while true; do
          sleep $$BACKUP_INTERVAL
          
          TIMESTAMP=$$(date +%Y%m%d_%H%M%S)
          
          if [ -f /data/db.sqlite ]; then
            echo "üì¶ Creating backup: backup_$$TIMESTAMP.sqlite"
            cp /data/db.sqlite /backups/backup_$$TIMESTAMP.sqlite
            
            # Also create a "latest" symlink for easy access
            ln -sf backup_$$TIMESTAMP.sqlite /backups/backup_latest.sqlite
            
            # Clean up old backups (keep only last N days)
            find /backups -name "backup_*.sqlite" -type f -mtime +$$BACKUP_RETENTION_DAYS -delete
            
            BACKUP_COUNT=$$(find /backups -name "backup_*.sqlite" -type f | wc -l)
            echo "‚úÖ Backup complete. Total backups: $$BACKUP_COUNT"
          else
            echo "‚ö†Ô∏è  Database file not found, skipping backup"
          fi
        done
      '
    depends_on:
      - app

  # APN Bridge Server - HTTP API bridge to Alpha Protocol Network
  apn-bridge:
    build:
      context: .
      dockerfile: Dockerfile.apn-bridge
    container_name: pcg-apn-bridge
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    environment:
      - NODE_ID=apn_09465b95
      - WALLET_ADDRESS=0x09465b9572fb354fdf4e34040386f180d1ff0c2a3a668333bedee17b266a4b74
      - RELAY_URL=nats://nonlocal.info:4222
    networks:
      app-network:
        aliases:
          - apn-bridge
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Nginx - Reverse proxy router
  nginx:
    image: nginx:alpine
    container_name: pcg-nginx
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf:ro
      - frontend-dist:/app/frontend/dist:ro
    ports:
      - "8080:80"  # Exposed on 8080 to avoid conflict with host nginx
    depends_on:
      app:
        condition: service_healthy
      apn-bridge:
        condition: service_healthy
    networks:
      app-network:
        aliases:
          - nginx
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Cloudflare Tunnel for secure port forwarding
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: pcg-cloudflared
    restart: unless-stopped
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TUNNEL_TOKEN}
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    depends_on:
      nginx:
        condition: service_healthy
    networks:
      app-network:
        aliases:
          - cloudflared

volumes:
  repos_data:
    driver: local
  frontend-dist:
    driver: local

networks:
  app-network:
    driver: bridge
