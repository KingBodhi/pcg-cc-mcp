[package]
name = "nora"
version = "0.0.96"
edition = "2021"
description = "Nora - Executive AI Assistant with Advanced Voice Capabilities"

[dependencies]
# Async runtime and web framework
tokio = { workspace = true, features = ["full"] }
axum = { workspace = true, features = ["ws"] }
tower-http = { workspace = true }
futures = "0.3"

# Serialization
serde = { workspace = true }
serde_json = "1.0"

# Error handling
anyhow = { workspace = true }
thiserror = { workspace = true }

# Logging
tracing = { workspace = true }

# Type generation and schemas
ts-rs = { workspace = true }
schemars = { workspace = true }

# HTTP client for external APIs
reqwest = { version = "0.11", features = ["json", "multipart", "stream"] }
bytes = "1.5"

# Audio processing (for voice capabilities)
tokio-tungstenite = "0.20"
base64 = "0.21"
uuid = { version = "1.0", features = ["v4"] }

# Time handling
chrono = { version = "0.4", features = ["serde"] }

# Configuration
config = "0.13"
dotenv = "0.15"

# Encryption for secure conversations
ring = "0.17"

# Database integration
sqlx = { version = "0.8.6", features = ["runtime-tokio-rustls", "sqlite", "chrono", "uuid"] }
db = { path = "../db" }

# British language patterns and NLP
regex = "1.9"
once_cell = "1.20"

# Additional dependencies for voice processing
async-trait = "0.1"

# LRU cache for LLM response caching
moka = { version = "0.12", features = ["future"] }

# Audio processing (these will be used by the voice engine)
# Note: In a real implementation, you'd add actual audio processing libraries
# For now, we'll use base64 for audio data encoding/decoding

[dev-dependencies]
tokio-test = "0.4"
